---
layout:     post
title:      UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS
subtitle:   论文笔记
date:       2019-07-06
author:     enoshx
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - GAN
    - unsupervised
    - paper
---

# 题目思考

CGAN是加conditional的GAN，此篇文章是unsupervised learning的，是否有将两者结合起来的文章


# 稳定 GAN
'''
Architecture guidelines for stable Deep Convolutional GANs 
• Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).
• Use batchnorm in both the generator and the discriminator. 
• Remove fully connected hidden layers for deeper architectures. 
• Use ReLU activation in generator for all layers except for the output, which uses Tanh. 
• Use LeakyReLU activation in the discriminator for all layers.
'''
## note
global average pooling increased model stability but hurt convergence speed.

Directly applying batchnorm to all layers however, resulted in sample oscillation and model instability. This was avoided by not applying batchnorm to the generator output layer and the discriminator input layer.